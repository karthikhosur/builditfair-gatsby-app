---
title: You may have missed your job opportunity because of AI
category: Case Studies
author: Karthik Hosur
date: 2022-10-20
---

## What is the Problem?

Many start-up companies are launching services that use AI to streamline the employee recruiting process. The technology enables hiring companies to assess many more applicants by analyzing and interpreting a huge volume of candidate data quickly and cost effectively. But caution needs to be applied here, because the basis of the selection decisions must be legally defensible. That’s not going to happen if you can’t open the black box of AI.

In addition, professional recruiters, particularly those in regulated industries such as financial services, should always know the basis for any selection decision. If it’s not possible to justify exactly why a candidate has been rejected from the application process, it leaves the company vulnerable to a legal challenge from that individual. Inherent bias in automated systems for hiring can result in a legal nightmare.

In one high profile example, Amazon developed an AI recruiting tool that went back and analyzed 10 years of employment applications in order to create a system that automatically identified characteristics of high-performing employees and against those standards, scored new candidates. The tool made headlines in 2018 when it was determined that the algorithm favored male candidates due to societal influences such as gender bias and wage gaps in technology jobs.

We cannot stop building smarter systems but we need to ensure to build it fair.

## How to fix it?

To ensure fairness and legality in the use of AI for employee recruitment, it is important to prioritize transparency, interpretability, and accountability in the development and deployment of such systems. This means designing algorithms and models that are capable of providing clear and defensible rationales for their selection decisions, and ensuring that they do not perpetuate biases or discriminate against any individual or group based on factors such as gender, race, or ethnicity.

One way to achieve this is to incorporate techniques such as explainability and fairness into the development process, which enable users to understand how the system is making decisions and what factors are contributing to its outputs. Additionally, it is important to involve experts and stakeholders from diverse fields, including human resources, ethics, and computer science, in the development and deployment of AI systems for employee recruitment.

Ultimately, building fair and legally defensible AI systems for employee recruitment requires a multi-disciplinary approach that prioritizes transparency, interpretability, and accountability. By doing so, we can ensure that these systems are capable of identifying the most qualified candidates while also ensuring that they are aligned with ethical and legal principles.