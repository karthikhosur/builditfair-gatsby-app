---
title:  Who is responsible if an autonomous car crashes?
category: Case Studies
author: Karthik Hosur
date: 2022-06-20
---
Accountability issues with regards to limitations and unintended consequences of AI applications in autonomous systems is increasingly becoming a hotly debated topic in news media, and a growing body of literature has begun to address concepts such as algorithmic accountability and responsible AI.

Algorithmic accountability, is defined to deal with the delegation of responsibility for damages incurred as a result of algorithmically-based decisions producing discriminatory or unfair consequences. This can also be applied to accountability issues in developments in algorithms and their social effects and consequences.In the event of damages incurred, responsible systems should include a mechanism for redress.

One area with regards to accountability issues is the introduction of self-driving vehicles. In the event of an accident, who should be held accountable? Autonomy, which, in the case of data-driven applications is very much dependent on algorithms designed to perform necessary functions, is a key area of focus with regards to self-driving vehicles, but it also raises issues of accountability.

Regulations for self-driving vehicle 28 Caplan, R., Donovan, J., Hanson, L. and Matthews, J. (2018). Algorithmic Accountability: A Primer, NYC: Data & Society. 29 Jfr. Diakopoulos, N. (2015). Algorithmic accountability: Journalistic investigation of computational power structures. Digital Journalism, 3(3), 398-415; 30 Hildebrandt, M. (2015). Smart Technologies and the Ends of Law, UK & USA: Edward Elgar Publishing; see also Larsson (2019). 31 Larsson 2019, s. 351. 1 7 I. Review of AI and ETHICS CONTENTS technology are currently being drafted in a number of countries, including Sweden (SOU 2018:16),32 where accountability is of crucial importance in traffic accidents – a topic that has been discussed for some time in the literature.

These problems have been highlighted not least in connection with deadly accidents involving autonomous vehicles, resulting in a need to evaluate and judge this mix of software, (safety) drivers, vehicle hardware, and external events. In 2016, a Tesla Model S equipped with radar and cameras determined that a nearby lorry was in fact the sky, which resulted in a fatal accident. In March 2018, a car used by Uber in self-driving vehicle trials hit and killed a woman in Arizona, USA, which raised extensive discussions on responsibility issues and self-driving vehicles in public traffic. Even if comparisons between traffic situations with and without self-driving vehicles were to show that autonomous vehicles are significantly safer, incidents like this will continue to have a detrimental impact on people’s trust and their acceptance of highly autonomous vehicles.

